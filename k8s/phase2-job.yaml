apiVersion: batch/v1
kind: Job
metadata:
  name: eagle-hallushift-phase2
  labels:
    project: eagle-hallushift
    phase: "2"
spec:
  backoffLimit: 2
  template:
    metadata:
      labels:
        project: eagle-hallushift
        phase: "2"
    spec:
      restartPolicy: Never
      tolerations:
      - key: "accelerator"
        operator: "Equal"
        value: "h200"
        effect: "NoSchedule"
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "gpu-request"
        operator: "Equal"
        value: "8"
        effect: "NoSchedule"
      containers:
      - name: phase2
        image: pytorch/pytorch:2.2.0-cuda12.1-cudnn8-devel
        resources:
          limits:
            nvidia.com/gpu: 8
          requests:
            nvidia.com/gpu: 8
            memory: "640Gi"
            cpu: "64"
        env:
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: eagle-hallushift-secrets
              key: hf-token
        - name: WANDB_API_KEY
          valueFrom:
            secretKeyRef:
              name: eagle-hallushift-secrets
              key: wandb-api-key
        command:
        - /bin/bash
        - -c
        - |
          set -e
          echo "=== Phase 2: Delta + Entropy Training ==="

          # Install system dependencies
          apt-get update && apt-get install -y git

          # Clone repo first
          git clone https://github.com/KilJaeeun/eagle-hallu-shift-idea.git
          cd eagle-hallu-shift-idea

          # Clone and install EAGLE (use commit compatible with EAGLE2 models)
          if [ ! -d "EAGLE" ]; then
            git clone https://github.com/SafeAILab/EAGLE.git
            cd EAGLE
            git checkout 79d6f79  # Commit compatible with yuhuili/EAGLE-llama2-chat-7B
            cd ..
          fi
          pip install -e EAGLE

          # Upgrade PyTorch for H200 support
          pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121
          pip install "accelerate>=0.26.0"
          # Pin transformers to avoid compatibility issues
          pip install "transformers>=4.40.0,<4.44.0"

          # Install additional dependencies
          pip install scipy tqdm deepspeed wandb huggingface_hub[cli]

          # Refresh shell hash table
          hash -r
          export PATH="/opt/conda/bin:$PATH"

          # Login
          python -c "from huggingface_hub import login; login(token='$HF_TOKEN')"
          wandb login $WANDB_API_KEY

          # Download training data
          mkdir -p data
          python -c "
import json
sample_data = [
    {'conversations': [{'from': 'human', 'value': 'What is machine learning?'}, {'from': 'gpt', 'value': 'Machine learning is a subset of AI.'}]},
    {'conversations': [{'from': 'human', 'value': 'Explain neural networks.'}, {'from': 'gpt', 'value': 'Neural networks are computing systems inspired by biological neural networks.'}]}
] * 100
with open('data/sharegpt_train.json', 'w') as f:
    json.dump(sample_data, f)
print('Created sample training data')
"

          # Phase 2 Ablation Study
          # Config A: Baseline (no aux loss)
          echo "=== Config A: Baseline ==="
          deepspeed --num_gpus=8 scripts/phase1_train.py \
            --base_model meta-llama/Llama-2-7b-chat-hf \
            --data_path data/sharegpt_train.json \
            --lambda_consistency 0.0 \
            --num_epochs 3 \
            --output_dir checkpoints/ablation_A_baseline \
            --wandb_run_name "ablation_A_baseline"

          # Config B: Consistency only
          echo "=== Config B: Consistency Only ==="
          deepspeed --num_gpus=8 scripts/phase1_train.py \
            --base_model meta-llama/Llama-2-7b-chat-hf \
            --data_path data/sharegpt_train.json \
            --lambda_consistency 0.1 \
            --num_epochs 3 \
            --output_dir checkpoints/ablation_B_consistency \
            --wandb_run_name "ablation_B_consistency"

          # Config C: Delta only
          echo "=== Config C: Delta Only ==="
          deepspeed --num_gpus=8 scripts/phase2_train.py \
            --base_model meta-llama/Llama-2-7b-chat-hf \
            --data_path data/sharegpt_train.json \
            --lambda_consistency 0.0 \
            --lambda_delta 0.1 \
            --num_epochs 3 \
            --output_dir checkpoints/ablation_C_delta \
            --wandb_run_name "ablation_C_delta"

          # Config D: Attention Entropy only
          echo "=== Config D: Entropy Only ==="
          deepspeed --num_gpus=8 scripts/phase2_train.py \
            --base_model meta-llama/Llama-2-7b-chat-hf \
            --data_path data/sharegpt_train.json \
            --lambda_consistency 0.0 \
            --lambda_delta 0.0 \
            --use_attention_entropy \
            --num_epochs 3 \
            --output_dir checkpoints/ablation_D_entropy \
            --wandb_run_name "ablation_D_entropy"

          # Config E: Consistency + Delta
          echo "=== Config E: Consistency + Delta ==="
          deepspeed --num_gpus=8 scripts/phase2_train.py \
            --base_model meta-llama/Llama-2-7b-chat-hf \
            --data_path data/sharegpt_train.json \
            --lambda_consistency 0.1 \
            --lambda_delta 0.1 \
            --num_epochs 3 \
            --output_dir checkpoints/ablation_E_cons_delta \
            --wandb_run_name "ablation_E_cons_delta"

          # Config F: Full (All three)
          echo "=== Config F: Full ==="
          deepspeed --num_gpus=8 scripts/phase2_train.py \
            --base_model meta-llama/Llama-2-7b-chat-hf \
            --data_path data/sharegpt_train.json \
            --lambda_consistency 0.1 \
            --lambda_delta 0.1 \
            --use_attention_entropy \
            --num_epochs 3 \
            --output_dir checkpoints/ablation_F_full \
            --wandb_run_name "ablation_F_full"

          # Upload all checkpoints
          huggingface-cli upload kje2952/eagle-hallu-shift checkpoints/ --repo-type model

          echo "=== Phase 2 Ablation Complete ==="
