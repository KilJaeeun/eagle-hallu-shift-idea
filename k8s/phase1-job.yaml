apiVersion: batch/v1
kind: Job
metadata:
  name: eagle-hallushift-phase1
  labels:
    project: eagle-hallushift
    phase: "1"
spec:
  backoffLimit: 2
  template:
    metadata:
      labels:
        project: eagle-hallushift
        phase: "1"
    spec:
      restartPolicy: Never
      tolerations:
      - key: "accelerator"
        operator: "Equal"
        value: "h200"
        effect: "NoSchedule"
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "gpu-request"
        operator: "Equal"
        value: "8"
        effect: "NoSchedule"
      containers:
      - name: phase1
        image: pytorch/pytorch:2.2.0-cuda12.1-cudnn8-devel
        resources:
          limits:
            nvidia.com/gpu: 8
          requests:
            nvidia.com/gpu: 8
            memory: "640Gi"  # 80GB per GPU
            cpu: "64"
        env:
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: eagle-hallushift-secrets
              key: hf-token
        - name: WANDB_API_KEY
          valueFrom:
            secretKeyRef:
              name: eagle-hallushift-secrets
              key: wandb-api-key
        command:
        - /bin/bash
        - -c
        - |
          set -e
          echo "=== Phase 1: Layer Consistency Training ==="

          # Install system dependencies
          apt-get update && apt-get install -y git

          # Clone repo first
          git clone https://github.com/KilJaeeun/eagle-hallu-shift-idea.git
          cd eagle-hallu-shift-idea

          # Clone and install EAGLE (use commit compatible with EAGLE2 models)
          if [ ! -d "EAGLE" ]; then
            git clone https://github.com/SafeAILab/EAGLE.git
            cd EAGLE
            git checkout 79d6f79  # Commit compatible with yuhuili/EAGLE-llama2-chat-7B
            cd ..
          fi
          pip install -e EAGLE

          # Upgrade PyTorch for H200 support
          pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121
          pip install "accelerate>=0.26.0"
          # Pin transformers to avoid compatibility issues
          pip install "transformers>=4.40.0,<4.44.0"

          # Install additional dependencies
          pip install scipy tqdm deepspeed wandb huggingface_hub[cli]

          # Refresh shell hash table
          hash -r
          export PATH="/opt/conda/bin:$PATH"

          # Login to services
          python -c "from huggingface_hub import login; login(token='$HF_TOKEN')"
          wandb login $WANDB_API_KEY

          # Download training data
          mkdir -p data
          # Download ShareGPT training data (or use subset for testing)
          python -c "
from huggingface_hub import hf_hub_download
import os
os.makedirs('data', exist_ok=True)
# For now, create a sample training data file for testing
# In production, download actual ShareGPT data
import json
sample_data = [
    {'conversations': [{'from': 'human', 'value': 'What is machine learning?'}, {'from': 'gpt', 'value': 'Machine learning is a subset of AI.'}]},
    {'conversations': [{'from': 'human', 'value': 'Explain neural networks.'}, {'from': 'gpt', 'value': 'Neural networks are computing systems inspired by biological neural networks.'}]}
] * 100  # Create 200 samples for testing
with open('data/sharegpt_train.json', 'w') as f:
    json.dump(sample_data, f)
print('Created sample training data with 200 samples')
"

          # Run Phase 1 training with different lambda values
          for LAMBDA in 0.01 0.1 0.5 1.0; do
            echo "=== Training with lambda=$LAMBDA ==="

            deepspeed --num_gpus=8 scripts/phase1_train.py \
              --base_model meta-llama/Llama-2-7b-chat-hf \
              --data_path data/sharegpt_train.json \
              --lambda_consistency $LAMBDA \
              --num_epochs 3 \
              --batch_size 1 \
              --lr 1e-5 \
              --gradient_checkpointing \
              --output_dir checkpoints/phase1_lambda$LAMBDA \
              --wandb_run_name "phase1_lambda$LAMBDA"

            # Upload checkpoint
            huggingface-cli upload kje2952/eagle-hallu-shift \
              checkpoints/phase1_lambda$LAMBDA \
              --repo-type model

          done

          echo "=== Phase 1 Complete ==="
